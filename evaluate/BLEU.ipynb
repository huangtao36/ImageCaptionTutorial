{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow: [github_vikasnar/Bleu](https://github.com/vikasnar/Bleu/blob/master/calculatebleu.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import codecs\n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "import json\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_file = './candidate.txt'\n",
    "ref_dir = './testSet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_data(cand, ref):\n",
    "    \"\"\" Store each reference and candidate sentences as a list \"\"\"\n",
    "    references = []\n",
    "    if '.txt' in ref:\n",
    "        reference_file = codecs.open(ref, 'r', 'utf-8')\n",
    "        references.append(reference_file.readlines())\n",
    "    else:\n",
    "        for root, dirs, files in os.walk(ref):\n",
    "            for f in files:\n",
    "                reference_file = codecs.open(os.path.join(root, f), 'r', 'utf-8')\n",
    "                references.append(reference_file.readlines())\n",
    "    candidate_file = codecs.open(cand, 'r', 'utf-8')\n",
    "    candidate = candidate_file.readlines()\n",
    "    return candidate, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate, references = fetch_data(cand_file, ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is a guide to action which ensures that the military always obeys the commands of the party.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['It is the guiding principle which guarantees the military forces always being under the command of the Party.'],\n",
       " ['It is the practical guide for the army always to heed the directions of the party.'],\n",
       " ['It is a guide to action that ensures that the military will forever heed Party commands.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接使用封装好的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 几何平均数\n",
    "def geometric_mean(precisions):\n",
    "    return (reduce(operator.mul, precisions)) ** (1.0 / len(precisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reduce() 函数会对参数序列中元素进行累积\n",
    "- 几何平均： $\\left ( \\prod_{n}^{i=1}x_{i} \\right )=\\sqrt[n]{x_{1}x_{2}...x_{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr: 0.8888888888888888, bp: 1.0\n",
      "pr: 0.5882352941176471, bp: 1.0\n",
      "pr: 0.4375, bp: 1.0\n",
      "pr: 0.26666666666666666, bp: 1.0\n",
      "BLEU:  0.49697705300310346\n"
     ]
    }
   ],
   "source": [
    "from calculatebleu import count_ngram, geometric_mean\n",
    "\n",
    "precisions = []\n",
    "for i in range(4):\n",
    "    pr, bp = count_ngram(candidate, references, i+1)\n",
    "    print(\"pr: {}, bp: {}\".format(pr, bp))\n",
    "    precisions.append(pr)\n",
    "bleu = geometric_mean(precisions) * bp\n",
    "print('BLEU: ', bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK中的评估方法\n",
    "nltk中有封装好的包，输入要求转换为单词列表  \n",
    "从下面的例子可以看出，结果和自己的代码计算出来的结果是一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "for reference in references:     # 这里有三个reference\n",
    "    ref_sentence = reference[0]  # str， 从列表中拿出来的句子\n",
    "    words = ref_sentence.strip().split()\n",
    "    ref_list.append(words)\n",
    "\n",
    "cand_sentence = candidate[0]\n",
    "cand_list = cand_sentence.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4969770530031034"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(ref_list, cand_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分离测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_grams = 2\n",
    "n = n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipped_count = 0\n",
    "count = 0\n",
    "r = 0\n",
    "c = 0\n",
    "\n",
    "# Calculate precision for each sentence\n",
    "ref_counts = []\n",
    "ref_lengths = []\n",
    "# Build dictionary of ngram counts\n",
    "for reference in references:\n",
    "    ref_sentence = reference[0]\n",
    "    ngram_d = {}\n",
    "    words = ref_sentence.strip().split()\n",
    "    \n",
    "    ref_lengths.append(len(words))\n",
    "    limits = len(words) - n + 1\n",
    "    \n",
    "    # loop through the sentance consider the ngram length\n",
    "    for i in range(limits):\n",
    "        ngram = ' '.join(words[i:i+n]).lower()\n",
    "        if ngram in ngram_d.keys():\n",
    "            ngram_d[ngram] += 1\n",
    "        else:\n",
    "            ngram_d[ngram] = 1\n",
    "    ref_counts.append(ngram_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref_counts: 是一个字典列表，每个字典为一句话的词块统计结果,   \n",
    "ref_lengths: 记录了三句话中，n_gram=2时的切割后的词块数量，也既是ref_counts中每一个字典的key的个数   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# candidate\n",
    "cand_sentence = candidate[0]\n",
    "cand_dict = {}\n",
    "words = cand_sentence.strip().split()\n",
    "limits = len(words) - n + 1\n",
    "for i in range(0, limits):\n",
    "    ngram = ' '.join(words[i:i + n]).lower()\n",
    "    if ngram in cand_dict:\n",
    "        cand_dict[ngram] += 1\n",
    "    else:\n",
    "        cand_dict[ngram] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cand_dict: 字典, candidate的词块统计结果  \n",
    "limits： cand_dict中key的个数，也是完全匹配的最高个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clip_count(cand_d, ref_ds):\n",
    "    \"\"\"Count the clip count for each ngram considering all references\"\"\"\n",
    "    count = 0\n",
    "    for m in cand_d.keys():\n",
    "        m_w = cand_d[m]\n",
    "        m_max = 0\n",
    "        for ref in ref_ds:\n",
    "            if m in ref:\n",
    "                m_max = max(m_max, ref[m])\n",
    "        m_w = min(m_w, m_max)\n",
    "        count += m_w\n",
    "    return count\n",
    "\n",
    "clipped_count += clip_count(cand_dict, ref_counts)\n",
    "count += limits\n",
    "clipped_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 16, 16]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_length_match(ref_l, cand_l):\n",
    "    \"\"\"Find the closest length of reference to that of candidate\"\"\"\n",
    "    least_diff = abs(cand_l-ref_l[0])\n",
    "    best = ref_l[0]\n",
    "    for ref in ref_l:\n",
    "        if abs(cand_l-ref) < least_diff:\n",
    "            least_diff = abs(cand_l-ref)\n",
    "            best = ref\n",
    "    return best\n",
    "\n",
    "r += best_length_match(ref_lengths, len(words))\n",
    "c += len(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if clipped_count == 0:\n",
    "    pr = 0\n",
    "else:\n",
    "    pr = float(clipped_count) / count\n",
    "    \n",
    "def brevity_penalty(c, r):\n",
    "    if c > r:\n",
    "        bp = 1\n",
    "    else:\n",
    "        bp = math.exp(1-(float(r)/c))\n",
    "    return bp\n",
    "\n",
    "bp = brevity_penalty(c, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5882352941176471"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_mean([pr]) * bp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
